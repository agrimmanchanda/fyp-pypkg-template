{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Experiment 2: Model Learning\n\nThe aim of this experiment was to remove multiple features from the data set\nsatisfying the Missing At Random (MAR) assumption and using the remainining \nfeatures to predict its values to emulate an actual imputer.\n\nThe data was removed in proportions: 10%, 30% and 50%.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries import\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Libraries generic\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Libraries sklearn\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Regressors\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom xgboost import XGBRegressor\n\n# Metrics\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import mean_squared_error\n\n# Custom Packages\nfrom labimputer.utils.load_dataset import remove_data_outliers\nfrom labimputer.utils.iter_imp import corr_pairs, get_score_statistics, rmse, norm_rmse, rmsle, get_test_scores, nae, get_best_models, get_cvts_stats, get_cvts_delta\nfrom labimputer.core.iter_imp import IterativeImputerRegressor, SimpleImputerRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define tuned estimators\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_TUNED_ESTIMATORS = {\n    'lr': LinearRegression(n_jobs=-1),\n    'dt': DecisionTreeRegressor(\n        criterion='mse',\n        splitter='best',\n        max_depth=8,\n        max_leaf_nodes=15,\n        min_samples_leaf=8,\n        min_samples_split=8,\n    ),\n    'rf': ExtraTreesRegressor(\n        n_estimators=100,\n        criterion='mse',\n        max_depth=8,\n        bootstrap=False,\n        warm_start=False,\n        n_jobs=-1,\n    ),\n    'svr': SGDRegressor(\n        alpha=1e-4,\n        epsilon=0.05,\n        learning_rate='adaptive',\n        loss='squared_epsilon_insensitive',\n        early_stopping=True,\n        warm_start=True,\n    ),\n    'knn': KNeighborsRegressor(\n        n_neighbors=8,\n        weights='distance',\n        n_jobs=-1,\n    ),\n    'xgb': XGBRegressor(\n        n_estimators=100,\n        eval_metric='rmse',\n        max_depth=10,\n        eta=0.2,\n        gamma=0.1,\n    ),\n    'mlp': MLPRegressor(\n        alpha=1e-4,\n        hidden_layer_sizes=32,\n        solver='adam',\n        learning_rate='invscaling',\n        warm_start=True,\n        early_stopping=True,\n    ),\n    'median': SimpleImputerRegressor(\n        strategy='median'\n    ),\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data import \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set relative data path and set FBC panel list\npath_data = '../resources/datasets/nhs/Transformed_First_FBC_dataset.csv'\n\n# Define FBC panel for the experiment\nFBC_CODES = sorted([\"EOS\", \"MONO\", \"BASO\", \"NEUT\", \"RBC\", \"WBC\", \n                \"MCHC\", \"MCV\", \"LY\", \"HCT\", \"RDW\", \"HGB\", \n                \"MCH\", \"PLT\", \"MPV\", \"NRBCA\"])\n\n# Read data and drop Nan _uid records\ndf = pd.read_csv(path_data).dropna(subset=['pid'])\n\n# Reset the index to easily count all test records\ndf.reset_index(drop=True, inplace=True)\n\n# Obtain the biomarkers DataFrame only\nraw_data = df[FBC_CODES].dropna(subset=FBC_CODES)\n\n# Remove outliers from dataset\ncomplete_profiles, _ = remove_data_outliers(raw_data)\n\n# Constant variables to drop\nDROP_FEATURES = ['BASO', 'NRBCA']\n\n# Complete profiles for complete case analysis\ncomplete_profiles = complete_profiles.drop(DROP_FEATURES, axis=1)\n\nFBC_PANEL = complete_profiles.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation matrix\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix using Pearson Correlation Coefficient\ncorr_mat = complete_profiles.corr(method='pearson')\n\n# Show\nprint(\"\\nData:\")\nprint(complete_profiles)\nprint(\"\\nCorrelation (pearson):\")\nprint(corr_mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split into train-test\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SEED = 8\n\n# Train-test split of 80:20\ntrain_set, test_set = train_test_split(complete_profiles, shuffle=False, test_size=0.2, random_state=8)\n\n# Use copy of the original train and test set\ntrain_copy, test_copy = train_set.copy(), test_set.copy()\n\n# Remove 10, 30 or 50% of values depending upon requirements\nfor col in train_copy.columns:\n    train_copy.loc[train_set.sample(frac=0.1).index, col] = np.nan\n    test_copy.loc[test_set.sample(frac=0.1).index, col] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Five fold cross validation (CVTS)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Number of splits\nn_splits = 5\n\n# Create Kfold instance\nskf = KFold(n_splits=n_splits, shuffle=False)\n\n# Scoring\nscoring = {\n    'nmae': 'neg_mean_absolute_error', # MAE\n    'nmse': 'neg_mean_squared_error',       # MSE\n    'nrmse': 'neg_root_mean_squared_error', # RMSE\n    'rmsle': make_scorer(rmsle), # RMSLE\n    'norm_rmse': make_scorer(norm_rmse), # NRMSE\n}\n\n# Compendium of results\niir_results = pd.DataFrame()\n\n# Create a list of estimators\nESTIMATORS = [\n    # 'lr',\n    # 'dt',\n    # 'rf',\n    # 'svr',\n    # 'knn',\n    # 'mlp',\n    # 'xgb',\n    # 'median',\n]\n\n# Concat scores for each CVTS run\ntest_data = pd.DataFrame()\n\n# Loop over each estimator\nfor i, est in enumerate(ESTIMATORS):\n\n    # Dictionary for storing all test scores on hold\n    test_scores = {}\n\n    # Check if estimator has been defined else skip\n    if est not in _TUNED_ESTIMATORS:\n        continue\n    \n    # Select estimator\n    estimator = _TUNED_ESTIMATORS[est]\n    \n    # Select imputer type\n    if est != 'median':\n        imputer = IterativeImputerRegressor(estimator=estimator,\n                                            min_value=0, \n                                            max_iter=10,\n                                            verbose=2,\n                                            imputation_order='descending')\n    else:\n        imputer = estimator\n\n    # Loop over each analyte\n    for biomarker in train_set:\n\n        # Generate new train-test for each run\n        aux_train = train_copy.copy()\n        aux_test = test_copy.copy()\n\n        # Define independent (X_train) and dependent (y_train) variables\n        X_train = aux_train[[x for x in aux_train.columns if x != biomarker]]\n        y_train = aux_train[biomarker]\n\n        # Define same variables with test set\n        X_test = aux_test[[x for x in aux_test.columns if x != biomarker]]\n        y_test = aux_test[biomarker]\n\n        # Information\n        print(\"\\n%s. Evaluating... %s for biomarker... %s\" % (i, est, biomarker))\n\n        # Create pipeline\n        pipe = Pipeline(steps=[ ('std', StandardScaler()),\n                                (est, imputer)],\n                        verbose=True)\n\n        # Obtain scores for each fold using cross_validate\n        scores = cross_validate(pipe, \n                                X_train, \n                                y_train, \n                                scoring=scoring, \n                                cv=skf, \n                                return_train_score=True, \n                                n_jobs=-1, \n                                verbose=0)\n\n        # Fit on training set \n        pipe.fit(X_train, y_train)\n\n        # Generate x, y test \n        y_pred = pipe.predict(X_test)\n\n        # Compendium of all test scores\n        test_scores[biomarker] = get_test_scores(y_test, y_pred)\n\n        # Extract results\n        results = pd.DataFrame(scores)\n        results.index = ['%s_%s_%s' % (biomarker, est, j)\n            for j in range(results.shape[0])]\n        \n        # Add to compendium of results\n        iir_results = iir_results.append(results)\n    \n    # Concatenate scores for the estimator to all other test scores\n    test_data = pd.concat([test_data, pd.Series(test_scores, name=est)], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Save\n# iir_results.to_csv('datasets/iir_mult_cv_results_10.csv')\n# test_data.to_csv('datasets/iir_mult_test_results_10.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of results from CVTS - 10%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Read CVTS results\ncvts_10 = pd.read_csv('datasets/iir_mult_cv_results_10.csv', index_col=0)\n\nmean_stats, std_stats = get_cvts_stats(cvts_10, FBC_PANEL)\n\nBEST_MODELS_10 = get_best_models(mean_stats)\n\nprint(\"Mean CVTS RMSE statistics (lowest score highlighted in green)\")\n\n# Highlighting the minimum values of last 2 columns\nmean_stats.style.highlight_min(color = 'lightgreen', \n                       axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting CVTS scores - 10%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define figure size\nplt.figure(figsize=(20,40))\n\n# Create new mean_stats df without the final row\nmean_stats_plot = mean_stats.head(mean_stats.shape[0] - 1)\n\n# Loop for each plot\nfor idx, (biomarker, scores) in enumerate(mean_stats_plot.iterrows(), start=1):\n    plt.subplot(7,2,idx)\n    plt.title(f'RMSE for {biomarker}',\n    fontweight='bold',\n    fontsize=14)\n    cmap = ['green' if (x == min(scores)) else 'royalblue' for x in scores]\n    scores.plot.barh(grid=True,\n                xerr=list(std_stats.loc[biomarker, :]),\n                align='center',\n                color=cmap)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.xlabel('RMSE Score', fontsize=16)\n\n# Space plots out\nplt.tight_layout()\n\n# Show\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare best CVTS with Simple Median Imputation - 10%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get Delta scores for 50% missing\ncvts_best_10 = get_cvts_delta(mean_stats, BEST_MODELS_10)\n\n# Plot figure\nplt.figure(figsize=(15,5))\n\n# Create barplot\nplot = sns.barplot(x=cvts_best_10.index, y=cvts_best_10['$\\Delta$ (%)'], hue=cvts_best_10['Model'], dodge=False)\n\n# Set xlabel as appropriate\nplot.set_xlabel(\"Analyte\")\n\n# Show\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of results from CVTS - 30%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Read CVTS results\ncvts_30 = pd.read_csv('datasets/iir_mult_cv_results_30.csv', index_col=0)\n\nmean_stats, std_stats = get_cvts_stats(cvts_30, FBC_PANEL)\n\nBEST_MODELS_30 = get_best_models(mean_stats)\n\nprint(\"Mean CVTS RMSE statistics (lowest score highlighted in green)\")\n\n# Highlighting the minimum values of last 2 columns\nmean_stats.style.highlight_min(color = 'lightgreen', \n                       axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting CVTS scores - 30%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define figure size\nplt.figure(figsize=(20,40))\n\n# Create new mean_stats df without the final row\nmean_stats_plot = mean_stats.head(mean_stats.shape[0] - 1)\n\n# Loop for each plot\nfor idx, (biomarker, scores) in enumerate(mean_stats_plot.iterrows(), start=1):\n    plt.subplot(7,2,idx)\n    plt.title(f'RMSE for {biomarker}',\n    fontweight='bold',\n    fontsize=14)\n    cmap = ['green' if (x == min(scores)) else 'royalblue' for x in scores]\n    scores.plot.barh(grid=True,\n                xerr=list(std_stats.loc[biomarker, :]),\n                align='center',\n                color=cmap)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.xlabel('RMSE Score', fontsize=16)\n\n# Space plots out\nplt.tight_layout()\n\n# Show\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare best CVTS with Simple Median Imputation - 30%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get Delta scores for 50% missing\ncvts_best_30 = get_cvts_delta(mean_stats, BEST_MODELS_30)\n\n# Plot figure\nplt.figure(figsize=(15,5))\n\n# Create barplot\nplot = sns.barplot(x=cvts_best_30.index, y=cvts_best_30['$\\Delta$ (%)'], hue=cvts_best_30['Model'], dodge=False)\n\n# Set xlabel as appropriate\nplot.set_xlabel(\"Analyte\")\n\n# Show\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of results from CVTS - 50%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Read CVTS results\ncvts_50 = pd.read_csv('datasets/iir_mult_cv_results_50.csv', index_col=0)\n\nmean_stats, std_stats = get_cvts_stats(cvts_50, FBC_PANEL)\n\nBEST_MODELS_50 = get_best_models(mean_stats)\n\nprint(\"Mean CVTS RMSE statistics (lowest score highlighted in green)\")\n\n# Highlighting the minimum values of last 2 columns\nmean_stats.style.highlight_min(color = 'lightgreen', \n                       axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting CVTS scores - 50%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define figure size\nplt.figure(figsize=(20,40))\n\n# Create new mean_stats df without the final row\nmean_stats_plot = mean_stats.head(mean_stats.shape[0] - 1)\n\n# Loop for each plot\nfor idx, (biomarker, scores) in enumerate(mean_stats_plot.iterrows(), start=1):\n    plt.subplot(7,2,idx)\n    plt.title(f'RMSE for {biomarker}',\n    fontweight='bold',\n    fontsize=14)\n    cmap = ['green' if (x == min(scores)) else 'royalblue' for x in scores]\n    scores.plot.barh(grid=True,\n                xerr=list(std_stats.loc[biomarker, :]),\n                align='center',\n                color=cmap)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.xlabel('RMSE Score', fontsize=16)\n\n# Space plots out\nplt.tight_layout()\n\n# Show\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare best CVTS with Simple Median Imputation - 50%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get Delta scores for 50% missing\ncvts_best_50 = get_cvts_delta(mean_stats, BEST_MODELS_50)\n\n# Plot figure\nplt.figure(figsize=(15,5))\n\n# Create barplot\nplot = sns.barplot(x=cvts_best_50.index, y=cvts_best_50['$\\Delta$ (%)'], hue=cvts_best_50['Model'], dodge=False)\n\n# Set xlabel as appropriate\nplot.set_xlabel(\"Analyte\")\n\n# Show\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}