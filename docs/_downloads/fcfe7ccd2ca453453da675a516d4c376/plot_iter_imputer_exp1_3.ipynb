{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Iterative Imputer Experiment I.III\n\nSingle biomarker removal using ``sklearn``\nmethods only.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries import\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Libraries generic\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\n\n# Libraries sklearn\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.preprocessing import StandardScaler\n\n# Regressors\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom xgboost import XGBRegressor\n\n# Metrics\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import mean_squared_error\n\n# Custom Packages\nfrom pkgname.utils.load_dataset import *\nfrom pkgname.utils.iter_imp import *\nfrom pkgname.core.iter_imp import IterativeImputerRegressor, SimpleImputerRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define tuned estimators\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_TUNED_ESTIMATORS = {\n    'lr': LinearRegression(),\n    'bridge': BayesianRidge(\n        alpha_1=1e-05,\n        alpha_2=1e-07,\n        lambda_1=1e-07,\n        lambda_2=1e-05,\n    ),\n    'dt': DecisionTreeRegressor(\n        criterion='mse',\n        splitter='best',\n        max_depth=8,\n        max_leaf_nodes=15,\n        min_samples_leaf=8,\n        min_samples_split=8,\n    ),\n    'etr': ExtraTreesRegressor(\n        n_estimators=100,\n        criterion='mse',\n        bootstrap=False,\n        warm_start=False,\n        n_jobs=-1,\n    ),\n    'sgd-ls': SGDRegressor(\n        alpha=1e-4,\n        epsilon=0.05,\n        learning_rate='adaptive',\n        loss='squared_loss',\n        early_stopping=True,\n        warm_start=True,\n    ),\n    'sgd-sv': SGDRegressor(\n        alpha=1e-4,\n        epsilon=0.01,\n        learning_rate='adaptive',\n        loss='squared_epsilon_insensitive',\n        early_stopping=True,\n        warm_start=True,\n    ),\n    'knn': KNeighborsRegressor(\n        n_neighbors=8,\n        weights='distance',\n        n_jobs=-1,\n    ),\n    'xgb': XGBRegressor(),\n    'mlp': MLPRegressor(\n        alpha=1e-4,\n        hidden_layer_sizes=32,\n        solver='adam',\n        learning_rate='invscaling',\n        warm_start=True,\n        early_stopping=True,\n    ),\n    'sir': SimpleImputerRegressor(\n        strategy='median'\n    ),\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data import \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set relative data path and set FBC panel list\npath_data = '../resources/datasets/nhs/Transformed_First_FBC_dataset.csv'\n\nFBC_CODES = [\"EOS\", \"MONO\", \"BASO\", \"NEUT\", \"RBC\", \"WBC\", \n                \"MCHC\", \"MCV\", \"LY\", \"HCT\", \"RDW\", \"HGB\", \n                \"MCH\", \"PLT\", \"MPV\", \"NRBCA\"]\n\n# Read data and drop Nan _uid records\ndf = pd.read_csv(path_data).dropna(subset=['pid'])\n\ndf.reset_index(drop=True, inplace=True)\n\n# Obtain the biomarkers DataFrame only\nraw_data = df[FBC_CODES].dropna(subset=FBC_CODES)\n\n# Remove outliers from dataset\ncomplete_profiles, _ = remove_data_outliers(raw_data)\n\n# Constant variables to drop\nDROP_FEATURES = ['BASO', 'NRBCA']\n\n# Complete profiles for complete case analysis\ncomplete_profiles = complete_profiles.drop(DROP_FEATURES, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation matrix\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix using Pearson Correlation Coefficient\ncorr_mat = complete_profiles.corr(method='pearson')\n\n# Show\nprint(\"\\nData:\")\nprint(complete_profiles)\nprint(\"\\nCorrelation (pearson):\")\nprint(corr_mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split complete profiles based on correlations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# split MCH-MCHC-MCV from the rest\n\nSPLIT_FEATURES = ['RBC', 'HCT', 'HGB']\ndf1 = complete_profiles[SPLIT_FEATURES] \ndf2 = complete_profiles[[x for x in complete_profiles.columns if x not in SPLIT_FEATURES]]\n\n\n# Number of splits\nn_splits = 5\n\n# Create Kfold instance\nskf = KFold(n_splits=n_splits, shuffle=False)\n\n# Scoring\nscoring = {\n    'nmae': 'neg_mean_absolute_error', # MAE\n    'nmse': 'neg_mean_squared_error',       # MSE\n    'nrmse': 'neg_root_mean_squared_error', # RMSE\n    #'norm_rmse': make_scorer(norm_rmse) # NRMSE\n}\n\n# Compendium of results\ncb_iir_results = pd.DataFrame()\n\n# Create a list of estimators\nESTIMATORS = [\n    'lr',\n    # 'bridge',\n    # 'dt',\n    # 'etr',\n    # 'sgd-ls',\n    # 'sgd-sv',\n    # 'knn',\n    # 'xgb',\n    # 'sir',\n]\n\n# Define datasets to obtain scores for\n_TEST_DATA = {\n    'cp': complete_profiles,\n    'df1': df1,\n    'df2': df2,\n}\n\n# For each estimator\nfor i, est in enumerate(ESTIMATORS):\n\n    data = pd.DataFrame()\n\n    # Check if estimator has been defined else skip\n    if est not in _TUNED_ESTIMATORS:\n        continue\n    \n    estimator = _TUNED_ESTIMATORS[est]\n    \n    if estimator != 'sir':\n        imputer = IterativeImputerRegressor(estimator=estimator)\n    else:\n        imputer = estimator\n\n    test_data = _TEST_DATA['df2']\n\n    for biomarker in test_data:\n\n        aux = test_data.copy(deep=True)\n        X = aux[[x for x in aux.columns if x != biomarker]]\n        y = aux[biomarker]\n\n        # Information\n        print(\"\\n%s. Evaluating... %s for biomarker... %s\" % (i, est, biomarker))\n\n        # Create pipeline\n        pipe = Pipeline(steps=[ ('std', StandardScaler()),\n                                (est, imputer)],\n                        verbose=True)\n\n        # Obtain scores for each fold using cross_validate\n        scores = cross_validate(pipe, \n                                X, \n                                y, \n                                scoring=scoring, \n                                cv=skf, \n                                return_train_score=True, \n                                n_jobs=-1, \n                                verbose=0)\n        \n        # Extract results\n        results = pd.DataFrame(scores)\n        results.index = ['%s_%s_%s' % (biomarker, est, j)\n            for j in range(results.shape[0])]\n        \n        # Add to compendium\n        cb_iir_results = cb_iir_results.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# # Save\ncb_iir_results.to_csv('datasets/cb_iir_results_df2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyse scores and test results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Combine the two DataFrame together\ncombined_df = pd.concat([df1, df2], axis=0)\n\n# Read results\ncompendium_df1 = pd.read_csv('datasets/cb_iir_results_df1.csv', index_col=0)\ncompendium_df2 = pd.read_csv('datasets/cb_iir_results_df2.csv', index_col=0)\n\n# Combine the two compendium together\ncombine_compendium = pd.concat([compendium_df1, compendium_df2], axis=0)\n\n# Obtain RMSE scores\nall_scores = get_score_statistics(combine_compendium, 'rmse')\n\n# Create DataFrame for mean and std dev statistics\nstatistics = pd.DataFrame(all_scores, index=combined_df.columns)\n\n# Rename the columns\nstatistics.columns = ['Mean', 'Std Dev']\n\n# Show the mean and std dev for linear regressor\nstatistics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}