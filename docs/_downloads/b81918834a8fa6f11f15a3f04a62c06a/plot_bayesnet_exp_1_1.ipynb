{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Bayesian Networks Experiment I.I\n\nUsing the ``pgmpy`` library to learn the \nstructure of Bayesian Network (BN) from the data,\nestimate parameters for Conditional Probability \nDistributions (CPDs) and imputing missing values. \nThis experiment uses discretisation as a \npre-processing step to optimise inference performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries import\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Libraries generic\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom math import isnan\n\n# Libraries for BNs\nimport networkx as nx\nfrom pgmpy.models import BayesianModel\nfrom pgmpy.estimators import HillClimbSearch, BDeuScore, BicScore, BayesianEstimator\nfrom pgmpy.inference import VariableElimination\n\n# Libraries sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.metrics import mean_squared_error\n\n# Custom Packages\nfrom labimputer.utils.load_dataset import remove_data_outliers\nfrom labimputer.core.bayes_net import BNImputer, learn_model_structure\nfrom labimputer.utils.bayes_net import get_unique_edges, get_score_statistics\nfrom labimputer.utils.load_dataset import suppress_stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data import \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set relative data path and set FBC panel list\npath_data = '../resources/datasets/nhs/Transformed_First_FBC_dataset.csv'\n\nFBC_CODES = [\"EOS\", \"MONO\", \"BASO\", \"NEUT\", \"RBC\", \"WBC\", \n                \"MCHC\", \"MCV\", \"LY\", \"HCT\", \"RDW\", \"HGB\", \n                \"MCH\", \"PLT\", \"MPV\", \"NRBCA\"]\n\n# Read data and drop Nan _uid records\ndf = pd.read_csv(path_data).dropna(subset=['pid'])\n\ndf.reset_index(drop=True, inplace=True)\n\n# Obtain the biomarkers DataFrame only\nraw_data = df[FBC_CODES].dropna(subset=FBC_CODES)\n\n# Remove outliers from dataset\ncomplete_profiles, _ = remove_data_outliers(raw_data)\n\n# Constant variables to drop\nDROP_FEATURES = ['BASO', 'NRBCA']\n\n# Complete profiles for complete case analysis\ncomplete_profiles = complete_profiles.drop(DROP_FEATURES, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Structure learning\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use the HillClimbSearch to find the best structure of the graph and use a \n# Bayesian Information Criterion (BIC) to set a score for the optimisation \n# problem being solved by HillClimbSearch. For convenience, code has been \n# commented as it takes a couple of minutes (with high CPU requirement) \n# to find the edges but the edges found are consistent for BIC and Bayesian\n# Dirichlet Equivalent Uniform (BDeu).\n\n# create a copy of the complete data\naux = complete_profiles.copy(deep=True)\n\n# discretise each feature into 5 uniform columns \nest = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\nXt = pd.DataFrame(est.fit_transform(aux), columns=complete_profiles.columns)\n\n# obtain train-test split to learn the structure of BN\ntrain, _ = train_test_split(Xt, test_size=0.2, shuffle=False)\n\n# learn the structure of BN using HillClimbSearch and BDeu score\nbest_model = learn_model_structure(train)\n\n# print the best edges found\nprint(best_model.edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model topology \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create an instance of Bayesian Model from pgmpy\nmodel = BNImputer(best_model.edges)\n\n# get only the variables found for BN\nFEATURES = get_unique_edges(best_model.edges)\n\n# update the data using features found\nbn_Xt = Xt[FEATURES]\n\n# obtain train-test split to learn the structure of BN\nbn_train, bn_test = train_test_split(bn_Xt, test_size=0.2, shuffle=False)\n\n# #######################################\n# # -------------------------------------\n# # Visualise BN\n# # -------------------------------------\n\nplt.figure(figsize=(20,10))\n\nnx.draw(model, node_size=2000, node_color='orange', font_weight='bold', with_labels=True)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameter learning\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# estimate the CPDs for each node in the BN\nmodel.fit(bn_train)\n\n# show the CPDs\nfor cpd in model.get_cpds():\n    print(f\"\\n {cpd}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove single biomarker\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bn_test = bn_test[:20]\n\nrmse_scores = {}\n\nfor idx, col in enumerate(bn_test):\n\n    aux = bn_test.copy()\n\n    aux[col] = np.nan\n\n    with suppress_stdout():\n        pred = model.imputer(aux)\n\n    ytrue = est.inverse_transform(bn_test)[:, idx]\n    ypred = est.inverse_transform(pred)[:, idx]\n\n    rmse = mean_squared_error(ytrue, ypred, squared=False)\n\n    rmse_scores[col] = rmse\n\n    print(f'RMSE for {col} is {rmse}')\n\n# Save\n# compendium = pd.DataFrame.from_dict(rmse_scores, orient='index')\n# compendium.to_csv('datasets/bn_results.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyse scores and test results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# read bn dataset\nbn_scores = pd.read_csv('datasets/bn_results.csv', index_col=0)\n\n# read iir dataset\niir_scores = pd.read_csv('datasets/iir_results.csv', index_col=0)\n\n# get the mean rmse for 5 folds\nmean_rmse = get_score_statistics(iir_scores, 'rmse')\n\n# Split scores to obtain score for each estimator\nsplit_scores = np.array_split(mean_rmse, 7)\n\n# Stack scores horizontally for easier plotting\nhsplit_scores = np.hstack((split_scores))\n\n# Create DataFrame for mean and std dev statistics\nstatistics = pd.DataFrame(hsplit_scores, index=complete_profiles.columns)\n\n# Get just mean RMSE\nmean_stats = statistics.iloc[:,::2]\n\nmean_stats = pd.concat([mean_stats, bn_scores], axis=1)\n\nmean_stats.columns = ['lr', 'bridge', 'dt', 'sgd-ls', 'sgd-sv', 'knn', 'sir', 'BN']\n\n# Highlighting the minimum values of last 2 columns\nmean_stats.style.highlight_min(color = 'lightgreen', axis = 1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}