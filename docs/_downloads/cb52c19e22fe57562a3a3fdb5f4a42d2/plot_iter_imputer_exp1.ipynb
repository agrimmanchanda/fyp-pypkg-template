{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Iterative Imputer Experiment I\n\nSingle biomarker removal experiment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the relevant libraries first\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom pkgname.utils.widgets import TidyWidget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data handling\nFirst, let's define the data set path and relevant variables of interest\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path_data = '../load_dataset/datasets/pathology-sample-march-may.csv'\n\nFBC_codes = [\"EOS\", \"MONO\", \"BASO\", \"NEUT\", \"RBC\", \"WBC\", \n                \"MCHC\", \"MCV\", \"LY\", \"HCT\", \"RDW\", \"HGB\", \n                \"MCH\", \"PLT\", \"MPV\", \"NRBCA\"]\n\nINTEREST_cols = [\"_uid\", \"orderCode\", \"result\", \"dateResult\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, import only variables of interest and FBC panel results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path_data, usecols=INTEREST_cols)\n\ndf = df.loc[df['orderCode'].isin(FBC_codes)]\n\ndf = df.dropna() # drop records of patients with NaN _uid\n\ndf.reset_index(drop=True, inplace=True)\n\n# Define function to set pid (patient ID) sorted by datetime\n\ndef change_pid_datetime_format(df):\n    df['pid'] = df['_uid'].str.extract('(\\d+)').astype(int)\n\n    pid_col = df.pop('pid')\n\n    df.insert(0, 'pid', pid_col)\n\n    df.drop('_uid', inplace=True, axis=1)\n\n    df.sort_values(by=['pid', 'dateResult'], inplace=True)\n\n    return df\n\n# Function to get highest correlation pairs \n\ndef corr_pairs(df):\n\n    # Code adapted from: \n    # https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas\n    df1 = pd.DataFrame([[i, j, df.corr().loc[i,j]] for i,j in list(itertools.combinations(df.corr(), 2))],columns=['var1', 'var2','corr'])    \n    \n    pairs = df1.sort_values(by='corr',ascending=False).head(5)\n    \n    return pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform data using TidyWidget\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Parameters\nindex = ['_uid', 'dateResult', 'orderCode']\nvalue = 'result'\n\n# Create widget\nwidget = TidyWidget(index=index, value=value)\n\n# Transform (keep all)\ntransform, duplicated = \\\n    widget.transform(df, report_duplicated=True)\n\n# Set pid for each patient and sort accordingly\ntransform_fmt = change_pid_datetime_format(transform)\n\n# Transform (keep first)\ntransform_first = \\\n    widget.transform(df, keep='first')\n\n# Set pid for each patient and sort accordingly\ntransform_first_fmt = change_pid_datetime_format(transform_first)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split data into input and output\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Obtain the biomarkers DataFrame only\nbiomarkers_df = transform_fmt.iloc[:,2:].dropna()\nbiomarkers_original_df_copy = biomarkers_df.copy()\n\nbiomarkers_data = biomarkers_df.values\n\n# Obtain highest correlation pairs Pearson Correlation Coefficient\nbiomarkers_highest_corr = corr_pairs(biomarkers_df)\n\n# Find biomarkers that are to be dropped from the dataset\nbiomarkers_to_drop = np.unique(biomarkers_highest_corr[['var1', 'var2']].values)\n\nprint(\"\\nBiomarkers with high correlations: \", biomarkers_to_drop)\n\n# TODO: should biomarkers be completely discarded from dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing step: normalise\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define min-max scaler and normalise dataset\nmin_max_scaler = preprocessing.MinMaxScaler()\nval_scaled = min_max_scaler.fit_transform(biomarkers_data)\nbiomarkers_df = pd.DataFrame(val_scaled)\nbiomarkers_copy_df = biomarkers_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Iterative Imputer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# dictionary to store mse scores for each biomarker\nmse_scores = {}\n\nfor biomarker in biomarkers_df.columns:\n\n    # Use a clean copy of the normalised data set\n    bm_copy_df = biomarkers_df.copy(deep=True)\n\n    # Randomly remove 50% of values and set to NaN\n    #bm_copy_df.loc[bm_copy_df.sample(frac=0.5).index, biomarker] = np.nan\n\n    # Strictly set every second value of the biomarker to NaN\n    col_pos = bm_copy_df.columns.get_loc(biomarker)\n    bm_copy_df.iloc[1::2, col_pos] = np.nan\n\n    # Define imputer \n    imputer = IterativeImputer()\n\n    # Fit on the dataset\n    biomarker_tansformed_data = imputer.fit_transform(bm_copy_df)\n\n    # Make dataframe of imputed data\n    imputed_data = pd.DataFrame(data=biomarker_tansformed_data, index=[i for i in range(biomarker_tansformed_data.shape[0])], columns=[col for col in biomarkers_df.columns])\n\n    # Compute true and obtain real value\n    val_pred = imputed_data[biomarker].values\n    val_true = biomarkers_copy_df[biomarker].values\n\n    # Calculate MSE scores from the true and predicted values\n    mse_score = mean_squared_error(val_true, val_pred)\n\n    # Store it in the mse_scores dict\n    mse_scores[biomarker] = mse_score\n\n# Create DataFrame of the dictionary\nmse_df = pd.DataFrame(mse_scores.items(), columns=['Biomarker', 'MSE Score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting MSE Scores\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cols = [col for col in biomarkers_original_df_copy.columns]\nax = mse_df.plot.bar(x='Biomarker', y='MSE Score', rot=0, grid=True, legend=False)\nax.set_title('MSE Scores for 50 percent missing biomarkers', fontdict={'fontsize': 15, 'fontweight': 'bold'})\nax.set_ylabel('MSE Score', fontsize=12)\nax.set_xlabel('Biomarker', fontsize=12)\nax.set_xticklabels(cols, rotation = 45, fontsize=12)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}