
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_examples\iterative_imputer\plot_iter_imputer_exp2_1_1.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download__examples_iterative_imputer_plot_iter_imputer_exp2_1_1.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__examples_iterative_imputer_plot_iter_imputer_exp2_1_1.py:


Experiment 2: Model Evaluation
===========================================

The aim of this experiment was to remove multiple features from the data set
satisfying the Missing At Random (MAR) assumption and using the remainining 
features to predict its values to emulate an actual imputer.

The data was removed in proportions: 10%, 30% and 50%.

.. GENERATED FROM PYTHON SOURCE LINES 14-17

-------------------------------------
Libraries import
-------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 17-57

.. code-block:: default
   :lineno-start: 18


    # Libraries generic
    import numpy as np
    import pandas as pd
    import sklearn
    import seaborn as sns
    import matplotlib.pyplot as plt
    import warnings
    warnings.filterwarnings("ignore")
    from scipy import stats

    # Libraries sklearn
    from sklearn.pipeline import Pipeline
    from sklearn.model_selection import KFold
    from sklearn.model_selection import cross_validate
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split


    # Regressors
    from sklearn.linear_model import LinearRegression
    from sklearn.linear_model import Ridge
    from sklearn.linear_model import BayesianRidge
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import ExtraTreesRegressor
    from sklearn.linear_model import SGDRegressor
    from sklearn.neighbors import KNeighborsRegressor
    from sklearn.neural_network import MLPRegressor
    from xgboost import XGBRegressor

    # Metrics
    from sklearn.metrics import make_scorer
    from sklearn.metrics import mean_squared_error

    # Custom Packages
    from labimputer.utils.load_dataset import remove_data_outliers
    from labimputer.utils.iter_imp import corr_pairs, get_score_statistics, rmse, norm_rmse, rmsle, get_test_scores, nae, get_best_models, get_cvts_stats
    from labimputer.core.iter_imp import IterativeImputerRegressor, SimpleImputerRegressor








.. GENERATED FROM PYTHON SOURCE LINES 58-61

-------------------------------------
Define tuned estimators
-------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 61-112

.. code-block:: default
   :lineno-start: 61

    _TUNED_ESTIMATORS = {
        'lr': LinearRegression(n_jobs=-1),
        'dt': DecisionTreeRegressor(
            criterion='mse',
            splitter='best',
            max_depth=6,
            max_leaf_nodes=12,
            min_samples_leaf=8,
            min_samples_split=8,
        ),
        'rf': ExtraTreesRegressor(
            n_estimators=10,
            criterion='mse',
            max_depth=6,
            bootstrap=False,
            warm_start=False,
            n_jobs=-1,
        ),
        'svr': SGDRegressor(
            alpha=1e-4,
            epsilon=0.01,
            learning_rate='adaptive',
            loss='squared_epsilon_insensitive',
            early_stopping=True,
            warm_start=True,
        ),
        'knn': KNeighborsRegressor(
            n_neighbors=7,
            weights='distance',
            n_jobs=-1,
        ),
        'xgb': XGBRegressor(
            n_estimators=10,
            eval_metric='rmse',
            max_depth=6,
            eta=0.2,
            gamma=0.1,
        ),
        'mlp': MLPRegressor(
            alpha=1e-4,
            hidden_layer_sizes=(32,64),
            solver='adam',
            learning_rate='invscaling',
            warm_start=True,
            early_stopping=True,
        ),
        'median': SimpleImputerRegressor(
            strategy='median'
        ),
    }








.. GENERATED FROM PYTHON SOURCE LINES 113-116

-------------------------------------
Data import 
-------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 116-145

.. code-block:: default
   :lineno-start: 117


    # Set relative data path and set FBC panel list
    path_data = '../resources/datasets/nhs/Transformed_First_FBC_dataset.csv'

    # Define FBC panel for the experiment
    FBC_CODES = sorted(["EOS", "MONO", "BASO", "NEUT", "RBC", "WBC", 
                    "MCHC", "MCV", "LY", "HCT", "RDW", "HGB", 
                    "MCH", "PLT", "MPV", "NRBCA"])

    # Read data and drop Nan _uid records
    df = pd.read_csv(path_data).dropna(subset=['pid'])

    # Reset the index to easily count all test records
    df.reset_index(drop=True, inplace=True)

    # Obtain the biomarkers DataFrame only
    raw_data = df[FBC_CODES].dropna(subset=FBC_CODES)

    # Remove outliers from dataset
    complete_profiles, _ = remove_data_outliers(raw_data)

    # Constant variables to drop
    DROP_FEATURES = ['BASO', 'NRBCA']

    # Complete profiles for complete case analysis
    complete_profiles = complete_profiles.drop(DROP_FEATURES, axis=1)

    FBC_PANEL = complete_profiles.columns








.. GENERATED FROM PYTHON SOURCE LINES 146-149

-------------------------------------
Correlation matrix
-------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 149-159

.. code-block:: default
   :lineno-start: 150


    # Calculate correlation matrix using Pearson Correlation Coefficient
    corr_mat = complete_profiles.corr(method='pearson')

    # Show
    print("\nData:")
    print(complete_profiles)
    print("\nCorrelation (pearson):")
    print(corr_mat)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Data:
            EOS   HCT    HGB   LY   MCH   MCHC    MCV  MONO   MPV  NEUT    PLT   RBC   RDW   WBC
    0       0.0  0.39  125.0  0.7  29.6  320.0   92.6   0.4   8.6   3.9  202.0  4.23  15.1   5.0
    6       0.0  0.37  113.0  1.1  32.0  307.0  104.0   0.7   7.4   4.0  257.0  3.53  15.1   5.9
    7       0.1  0.34  110.0  0.8  32.2  320.0  101.0   0.3   8.0   3.0  282.0  3.40  13.8   4.2
    8       0.1  0.34  108.0  0.7  32.5  321.0  101.0   0.3   8.1   3.4  282.0  3.32  14.4   4.5
    9       0.2  0.34  109.0  0.7  32.7  320.0  102.0   0.6   8.7   4.6  298.0  3.34  14.1   6.1
    ...     ...   ...    ...  ...   ...    ...    ...   ...   ...   ...    ...   ...   ...   ...
    101167  0.1  0.42  138.0  2.1  29.8  328.0   90.8   0.4   9.6   4.4  210.0  4.62  11.3   7.1
    101169  0.2  0.38  128.0  2.0  29.5  334.0   88.2   0.4   9.3   4.9  208.0  4.33  12.9   7.6
    101170  0.2  0.42  134.0  2.2  28.7  323.0   88.8   0.4   8.9   4.0  295.0  4.67  13.9   6.8
    101173  0.0  0.37  122.0  2.1  29.0  325.0   89.4   0.6  10.5   4.5  247.0  4.19  11.1   7.2
    101174  0.0  0.37  121.0  1.2  30.1  326.0   92.4   0.8   9.2   8.1  204.0  4.01  11.7  10.1

    [56271 rows x 14 columns]

    Correlation (pearson):
               EOS       HCT       HGB        LY       MCH      MCHC  ...       MPV      NEUT       PLT       RBC       RDW       WBC
    EOS   1.000000  0.075691  0.063382  0.289178 -0.046216 -0.073132  ... -0.008346 -0.077021  0.148320  0.076247 -0.029017  0.063383
    HCT   0.075691  1.000000  0.983795  0.368346  0.018124 -0.009970  ...  0.156687 -0.147780  0.044596  0.932916 -0.445215 -0.034098
    HGB   0.063382  0.983795  1.000000  0.367455  0.084460  0.160611  ...  0.148419 -0.142903  0.030526  0.921963 -0.479547 -0.030376
    LY    0.289178  0.368346  0.367455  1.000000 -0.079429  0.021764  ...  0.133033 -0.067306  0.227641  0.381424 -0.258299  0.242921
    MCH  -0.046216  0.018124  0.084460 -0.079429  1.000000  0.391104  ... -0.073755 -0.036335 -0.169143 -0.301421 -0.354513 -0.058005
    MCHC -0.073132 -0.009970  0.160611  0.021764  0.391104  1.000000  ... -0.041123  0.014154 -0.087255  0.002774 -0.237056  0.015221
    MCV  -0.016068  0.024410  0.016983 -0.097091  0.902952 -0.040685  ... -0.061824 -0.046127 -0.143448 -0.328603 -0.273143 -0.070355
    MONO  0.176592 -0.011767 -0.011822  0.228941 -0.007282 -0.006352  ...  0.006449  0.437707  0.191892 -0.011525  0.000838  0.565965
    MPV  -0.008346  0.156687  0.148419  0.133033 -0.073755 -0.041123  ...  1.000000 -0.015518 -0.329940  0.169995 -0.129583  0.021949
    NEUT -0.077021 -0.147780 -0.142903 -0.067306 -0.036335  0.014154  ... -0.015518  1.000000  0.204307 -0.125506  0.043472  0.946863
    PLT   0.148320  0.044596  0.030526  0.227641 -0.169143 -0.087255  ... -0.329940  0.204307  1.000000  0.089001 -0.050207  0.275886
    RBC   0.076247  0.932916  0.921963  0.381424 -0.301421  0.002774  ...  0.169995 -0.125506  0.089001  1.000000 -0.317913 -0.009884
    RDW  -0.029017 -0.445215 -0.479547 -0.258299 -0.354513 -0.237056  ... -0.129583  0.043472 -0.050207 -0.317913  1.000000 -0.031387
    WBC   0.063383 -0.034098 -0.030376  0.242921 -0.058005  0.015221  ...  0.021949  0.946863  0.275886 -0.009884 -0.031387  1.000000

    [14 rows x 14 columns]




.. GENERATED FROM PYTHON SOURCE LINES 160-163

-------------------------------------
Split into train-test
-------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 163-177

.. code-block:: default
   :lineno-start: 164


    SEED = 8

    # Train-test split of 80:20
    train_set, test_set = train_test_split(complete_profiles, shuffle=False, test_size=0.2, random_state=8)

    # Use copy of the original train and test set
    train_copy, test_copy = train_set.copy(), test_set.copy()

    # Remove 10, 30 or 50% of values depending upon requirements
    for col in train_copy.columns:
        train_copy.loc[train_set.sample(frac=0.1).index, col] = np.nan
        test_copy.loc[test_set.sample(frac=0.1).index, col] = np.nan








.. GENERATED FROM PYTHON SOURCE LINES 178-181

-------------------------------------
Five fold cross validation (CVTS)
-------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 181-188

.. code-block:: default
   :lineno-start: 182


    # Number of splits
    n_splits = 5

    # Create Kfold instance
    skf = KFold(n_splits=n_splits, shuffle=False)








.. GENERATED FROM PYTHON SOURCE LINES 189-192

------------------------------------
Obtain best RMSE scores from (CVTS)
------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 192-239

.. code-block:: default
   :lineno-start: 193


    # Define tested methods
    METHODS = [
        'LR',
        'DT',
        'RF',
        'SVR',
        'KNN',
        'MLP',
        'XGB',
        'Median',
    ]

    # Define FBC panel for the experiment
    FBC_PANEL = sorted(["EOS", "MONO", "NEUT", "RBC", "WBC", 
                    "MCHC", "MCV", "LY", "HCT", "RDW", "HGB", 
                    "MCH", "PLT", "MPV"])


    # Read CVTS results - 10%
    cvts_10 = pd.read_csv('datasets/iir_mult_cv_results_10.csv', index_col=0)

    # Mean and std stats
    mean_stats, std_stats = get_cvts_stats(cvts_10, FBC_PANEL)

    # Find the best models for 10
    BEST_MODELS_10 = get_best_models(mean_stats)

    # Read CVTS results - 30%
    cvts_30 = pd.read_csv('datasets/iir_mult_cv_results_30.csv', index_col=0)

    # Mean and std stats
    mean_stats, std_stats = get_cvts_stats(cvts_30, FBC_PANEL)

    # Find the best models for 30
    BEST_MODELS_30 = get_best_models(mean_stats)

    # Read CVTS results - 50%
    cvts_50 = pd.read_csv('datasets/iir_mult_cv_results_50.csv', index_col=0)

    # Mean and std stats
    mean_stats, std_stats = get_cvts_stats(cvts_50, FBC_PANEL)

    # Find the best models for 50
    BEST_MODELS_50 = get_best_models(mean_stats)









.. GENERATED FROM PYTHON SOURCE LINES 240-243

--------------------------------------------
Model evaluation on held out test set (HOTS)
--------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 243-308

.. code-block:: default
   :lineno-start: 244


    # Set to false to prevent running during script build
    run_eval = False

    if run_eval:

        # Collect relevant scores
        test_scores = pd.DataFrame()

        # Loop for each model in best models
        for biomarker, model in BEST_MODELS_10.items():

            for est in [model, 'median']:

                estimator = _TUNED_ESTIMATORS[est]

                # Select estimator
                if est != 'median':
                    imputer = IterativeImputerRegressor(estimator=estimator,
                                                        min_value=0, 
                                                        max_iter=10,
                                                        verbose=2,
                                                        imputation_order='descending')
                else:
                    imputer = estimator

                # Generate new train-test for each run
                aux_train = train_copy.copy()
                aux_test = test_copy.copy()

                # Define independent (X_train) and dependent (y_train) variables
                X_train = aux_train[[x for x in aux_train.columns if x != biomarker]]
                y_train = aux_train[biomarker]

                # Define same variables with test set
                X_test = aux_test[[x for x in aux_test.columns if x != biomarker]]
                y_test = aux_test[biomarker]

                nan_idx = np.argwhere(np.isnan(y_test.to_numpy())).flatten()

                # Information
                print("\n Evaluating... %s for biomarker... %s" % (est, biomarker))

                # Create pipeline
                pipe = Pipeline(steps=[ ('std', StandardScaler()),
                                        (est, imputer)],
                                verbose=True)

                # Fit on training set 
                pipe.fit(X_train, y_train)

                # Generate x, y test 
                y_pred = pipe.predict(X_test)[nan_idx]

                # Store results in DataFrame
                if est != 'median':
                    true_pred_vals = pd.DataFrame(list(zip(y_test, y_pred)),
                    columns=[f'{biomarker}-{est}-true', f'{biomarker}-{est}-pred'])
                else:
                    true_pred_vals = pd.Series(y_pred, name=f'{biomarker}-{est}')

                test_scores = pd.concat([test_scores, true_pred_vals], axis=1)

                test_scores.to_csv('datasets/iir_mult_test_results_10.csv')








.. GENERATED FROM PYTHON SOURCE LINES 309-312

----------------------------------------
RMSE for held out test set (HOTS) - 10%
----------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 312-370

.. code-block:: default
   :lineno-start: 313


    # Generate simple test results
    df = pd.read_csv('datasets/iir_mult_test_results_10.csv', index_col=0)

    # Split the model and median scores for each analyte
    split_data = np.split(df.T.to_numpy(), len(df.T.to_numpy())/3)

    # DataFrame for RMSE
    data = pd.DataFrame()

    # DataFrame for NAE
    nae_results = pd.DataFrame()

    # Iterate through the predicted and median scores
    for idx, values in enumerate(zip(split_data, FBC_PANEL)):
    
        # Extract the true and predicted values
        y_true, y_pred, y_med = values[0][0], values[0][1], values[0][2]
    
        # Obtain the RMSE scores
        rmse_tp, rmse_tm = rmse(y_true, y_pred), rmse(y_true, y_med)

        # Obtain NAE scores
        nae_tp, nae_tm = nae(y_true, y_pred), nae(y_true, y_med)
    
        nae_vals = pd.DataFrame([nae_tp, 
        ['Best (10%)' for _ in range(len(nae_tp))], 
        [values[1] for _ in range(len(nae_tp))]]).T
    
        nae_vals_med = pd.DataFrame([nae_tm, 
        ['Median' for _ in range(len(nae_tm))], 
        [values[1] for _ in range(len(nae_tm))]]).T
    
        # Join the RMSE results
        join_rmse = pd.concat([pd.Series(rmse_tp), pd.Series(rmse_tm)], axis=1)

        # Join the NAE results
        join_nae = pd.concat([nae_vals, nae_vals_med], axis=0)
    
        # Append
        data = data.append(join_rmse)
        nae_results = nae_results.append(join_nae)


    # Create column names and set index
    data.columns, data.index = ['Best', 'Median'], FBC_PANEL

    # Define delta column
    data['Delta (%)'] = 100 - (100* (data['Best']/data['Median']))

    # Set model type
    data['Model'] = ['Best (10%)' for i in range(data.shape[0])] 

    # Get mean scores for each model
    data.loc['Mean'] = data.mean()

    data






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Best</th>
          <th>Median</th>
          <th>Delta (%)</th>
          <th>Model</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>EOS</th>
          <td>0.090103</td>
          <td>0.114879</td>
          <td>21.567364</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>HCT</th>
          <td>0.006325</td>
          <td>0.065431</td>
          <td>90.333900</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>HGB</th>
          <td>1.921772</td>
          <td>22.780714</td>
          <td>91.564041</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>LY</th>
          <td>0.315319</td>
          <td>0.729753</td>
          <td>56.790998</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>MCH</th>
          <td>0.329815</td>
          <td>1.947581</td>
          <td>83.065394</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>MCHC</th>
          <td>3.858999</td>
          <td>9.788936</td>
          <td>60.577953</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>MCV</th>
          <td>1.046988</td>
          <td>5.426134</td>
          <td>80.704722</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>MONO</th>
          <td>0.126524</td>
          <td>0.249404</td>
          <td>49.269403</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>MPV</th>
          <td>0.983457</td>
          <td>1.102141</td>
          <td>10.768511</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>NEUT</th>
          <td>0.666165</td>
          <td>2.598097</td>
          <td>74.359515</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>PLT</th>
          <td>65.539792</td>
          <td>79.645033</td>
          <td>17.710133</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>RBC</th>
          <td>0.060371</td>
          <td>0.789619</td>
          <td>92.354420</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>RDW</th>
          <td>1.270040</td>
          <td>1.540732</td>
          <td>17.569008</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>WBC</th>
          <td>0.694917</td>
          <td>2.869431</td>
          <td>75.782045</td>
          <td>Best (10%)</td>
        </tr>
        <tr>
          <th>Mean</th>
          <td>5.493613</td>
          <td>9.260563</td>
          <td>58.744100</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 371-374

----------------------------------------
RMSE for HOTS - 30%
----------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 374-428

.. code-block:: default
   :lineno-start: 375


    # Generate simple test results
    df1 = pd.read_csv('datasets/iir_mult_test_results_30.csv', index_col=0)

    # Split the model and median scores for each analyte
    split_data1 = np.split(df1.T.to_numpy(), len(df1.T.to_numpy())/3)

    # DataFrame for data
    data1 = pd.DataFrame()

    # Iterate through the predicted and median scores
    for idx, values in enumerate(zip(split_data1, FBC_PANEL)):
    
        # Extract the true and predicted values
        y_true, y_pred, y_med = values[0][0], values[0][1], values[0][2]
    
        # Obtain the RMSE scores
        rmse_tp, rmse_tm = rmse(y_true, y_pred), rmse(y_true, y_med)

        # Obtain NAE scores
        nae_tp, nae_tm = nae(y_true, y_pred), nae(y_true, y_med)
    
        nae_vals = pd.DataFrame([nae_tp, 
        ['Best (30%)' for _ in range(len(nae_tp))], 
        [values[1] for _ in range(len(nae_tp))]]).T
    
        nae_vals_med = pd.DataFrame([nae_tm, 
        ['Median' for _ in range(len(nae_tm))], 
        [values[1] for _ in range(len(nae_tm))]]).T
    
        # Join the RMSE results
        join_rmse = pd.concat([pd.Series(rmse_tp), pd.Series(rmse_tm)], axis=1)

        # Join the NAE results
        join_nae = pd.concat([nae_vals, nae_vals_med], axis=0)
    
        # Append
        data1 = data1.append(join_rmse)
        nae_results = nae_results.append(join_nae)

    # Create column names and set index
    data1.columns, data1.index = ['Best', 'Median'], FBC_PANEL

    # Define delta column
    data1['Delta (%)'] = 100 - (100* (data1['Best']/data1['Median']))

    # Set model type
    data1['Model'] = ['Best (30%)' for i in range(data1.shape[0])] 

    # Get mean scores for each model
    data1.loc['Mean'] = data1.mean()

    data1






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Best</th>
          <th>Median</th>
          <th>Delta (%)</th>
          <th>Model</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>EOS</th>
          <td>0.109314</td>
          <td>0.115850</td>
          <td>5.641712</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>HCT</th>
          <td>0.020423</td>
          <td>0.066130</td>
          <td>69.116444</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>HGB</th>
          <td>6.902909</td>
          <td>22.106425</td>
          <td>68.774196</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>LY</th>
          <td>0.483985</td>
          <td>0.734849</td>
          <td>34.138203</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>MCH</th>
          <td>0.714884</td>
          <td>1.920345</td>
          <td>62.773161</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>MCHC</th>
          <td>6.535653</td>
          <td>9.705314</td>
          <td>32.659029</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>MCV</th>
          <td>2.377287</td>
          <td>5.406144</td>
          <td>56.026210</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>MONO</th>
          <td>0.186244</td>
          <td>0.254672</td>
          <td>26.868999</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>MPV</th>
          <td>1.021427</td>
          <td>1.120697</td>
          <td>8.857950</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>NEUT</th>
          <td>1.340191</td>
          <td>2.692306</td>
          <td>50.221458</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>PLT</th>
          <td>66.889308</td>
          <td>79.217693</td>
          <td>15.562666</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>RBC</th>
          <td>0.235855</td>
          <td>0.750995</td>
          <td>68.594292</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>RDW</th>
          <td>1.306967</td>
          <td>1.574901</td>
          <td>17.012737</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>WBC</th>
          <td>1.381880</td>
          <td>2.821100</td>
          <td>51.016287</td>
          <td>Best (30%)</td>
        </tr>
        <tr>
          <th>Mean</th>
          <td>6.393309</td>
          <td>9.177673</td>
          <td>40.518810</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 429-432

----------------------------------------
RMSE for for HOTS - 50%
----------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 432-486

.. code-block:: default
   :lineno-start: 433


    # Generate simple test results
    df2 = pd.read_csv('datasets/iir_mult_test_results_50.csv', index_col=0)

    # Split the model and median scores for each analyte
    split_data2 = np.split(df2.T.to_numpy(), len(df2.T.to_numpy())/3)

    # DataFrame for data
    data2 = pd.DataFrame()

    # Iterate through the predicted and median scores
    for idx, values in enumerate(zip(split_data2, FBC_PANEL)):
    
        # Extract the true and predicted values
        y_true, y_pred, y_med = values[0][0], values[0][1], values[0][2]
    
        # Obtain the RMSE scores
        rmse_tp, rmse_tm = rmse(y_true, y_pred), rmse(y_true, y_med)

        # Obtain NAE scores
        nae_tp, nae_tm = nae(y_true, y_pred), nae(y_true, y_med)
    
        nae_vals = pd.DataFrame([nae_tp, 
        ['Best (50%)' for _ in range(len(nae_tp))], 
        [values[1] for _ in range(len(nae_tp))]]).T
    
        nae_vals_med = pd.DataFrame([nae_tm, 
        ['Median' for _ in range(len(nae_tm))], 
        [values[1] for _ in range(len(nae_tm))]]).T
    
        # Join the RMSE results
        join_rmse = pd.concat([pd.Series(rmse_tp), pd.Series(rmse_tm)], axis=1)

        # Join the NAE results
        join_nae = pd.concat([nae_vals, nae_vals_med], axis=0)
    
        # Append
        data2 = data2.append(join_rmse)
        nae_results = nae_results.append(join_nae)

    # Create column names and set index
    data2.columns, data2.index = ['Best', 'Median'], FBC_PANEL

    # Define delta column
    data2['Delta (%)'] = 100 - (100 * (data2['Best']/data2['Median']))

    # Set model type
    data2['Model'] = ['Best (50%)' for i in range(data2.shape[0])] 

    # Get mean scores for each model
    data2.loc['Mean'] = data2.mean()

    data2






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Best</th>
          <th>Median</th>
          <th>Delta (%)</th>
          <th>Model</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>EOS</th>
          <td>0.111605</td>
          <td>0.116344</td>
          <td>4.072980</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>HCT</th>
          <td>0.030874</td>
          <td>0.064388</td>
          <td>52.049851</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>HGB</th>
          <td>10.357120</td>
          <td>22.101204</td>
          <td>53.137756</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>LY</th>
          <td>0.585180</td>
          <td>0.735011</td>
          <td>20.384848</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>MCH</th>
          <td>1.142801</td>
          <td>1.922698</td>
          <td>40.562626</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>MCHC</th>
          <td>8.443924</td>
          <td>9.870078</td>
          <td>14.449271</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>MCV</th>
          <td>3.368980</td>
          <td>5.455534</td>
          <td>38.246562</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>MONO</th>
          <td>0.210505</td>
          <td>0.257917</td>
          <td>18.382672</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>MPV</th>
          <td>1.051039</td>
          <td>1.121240</td>
          <td>6.260997</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>NEUT</th>
          <td>1.738254</td>
          <td>2.729048</td>
          <td>36.305466</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>PLT</th>
          <td>71.166608</td>
          <td>79.565129</td>
          <td>10.555531</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>RBC</th>
          <td>0.363401</td>
          <td>0.752655</td>
          <td>51.717502</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>RDW</th>
          <td>1.360892</td>
          <td>1.572347</td>
          <td>13.448359</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>WBC</th>
          <td>1.758843</td>
          <td>2.830022</td>
          <td>37.850562</td>
          <td>Best (50%)</td>
        </tr>
        <tr>
          <th>Mean</th>
          <td>7.263573</td>
          <td>9.220972</td>
          <td>28.387499</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 487-490

------------------------------------------------
Comparison of Delta to Simple Median Imputation
------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 490-512

.. code-block:: default
   :lineno-start: 491


    # Select all Delta and Model part of data
    pt1 = data[['Delta (%)', 'Model']][:-1]
    pt2 = data1[['Delta (%)', 'Model']][:-1]
    pt3 = data2[['Delta (%)', 'Model']][:-1]

    # Combined all Delta scores together
    comb_df = pd.concat([pt1, pt2, pt3], axis=0)

    # Figure
    plt.figure(figsize=(16,6))

    # Plot combined Delta scores
    plot_comb = sns.barplot(x=comb_df.index, y=comb_df['Delta (%)'], hue=comb_df['Model'])

    # Set the x label
    plot_comb.set_xlabel("Analyte")

    # Show
    plt.show()





.. image:: /_examples/iterative_imputer/images/sphx_glr_plot_iter_imputer_exp2_1_1_001.png
    :alt: plot iter imputer exp2 1 1
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 513-516

---------------------------------
NAE distribution for HOTS
---------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 516-530

.. code-block:: default
   :lineno-start: 517


    nae_results.columns = ['NAE', 'Model', 'Analyte']

    # Plot the figure
    plt.figure(figsize=(20,8))

    # Create grouped boxplot 
    sns.boxplot(x = nae_results['Analyte'],
            y = nae_results['NAE'],
            hue = nae_results['Model'],
            showfliers=False
            )

    # Show
    plt.show()


.. image:: /_examples/iterative_imputer/images/sphx_glr_plot_iter_imputer_exp2_1_1_002.png
    :alt: plot iter imputer exp2 1 1
    :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  23.269 seconds)


.. _sphx_glr_download__examples_iterative_imputer_plot_iter_imputer_exp2_1_1.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_iter_imputer_exp2_1_1.py <plot_iter_imputer_exp2_1_1.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_iter_imputer_exp2_1_1.ipynb <plot_iter_imputer_exp2_1_1.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
